---
title: "Land change & Streamflow"
author: "Sacha Siani and Taehee Hwang"
output: html_notebook
---

# Introduction

Fire is a big problem in the brasilian amazon (check Aragao papers).
  -Carbon stocks
  -Health issues
  -Biodiversity loss
  
The Amazon is the largest basin, aquifer, and river in the world. Water cicle in the Amazon is essential to ensure that the south of south america has enough rain. Still, X% of the Amazonian population does not access treated water supply. Flood affects X people.

Luiz Aragão and Paulo Brando talking about the ecological effects of fire https://www.youtube.com/watch?v=T899olLLP_c

In this report we evaluate the data available to analyse the effects of land cover changes, in particular fires, on hydrological dynamics in the Brazilian Amazon.

We use data from the National Water Agency (ANA).

```{r include=F, results=F}
library(tidyverse)
library(lubridate)
library(sf)
library(units)
```

First we load the shapefile with the points. We also filter by type of station and basin.

```{r include=F, results=F}
crs = "+proj=aea +lat_1=-2 +lat_2=-22 +lat_0=-12 +lon_0=-54 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs"

amazon <- st_read(
  dsn = "C:/Users/Siani/Box/geodata/amazon_basin/data/amzbasin.shp") %>% 
  st_transform(crs)

pts <- st_read(
  dsn = "../data/Estacoes_Rede_Hidrometeorologica_Nacional/Estacoes_Fluviometricas_e_Pluviometricas_da_Rede.shp") %>%
  filter(TIPOESTACA == 'Fluviométrica') %>%
  filter(BACIA == "RIO AMAZONAS") %>%
  st_transform(crs)
```

For the Amazonas River basin, we have `r nrow(pts)` water stations available.

```{r}
ggplot() +
  geom_sf(data = amazon, fill = "palegreen3", aes(color = "Amazon")) +
  ggnewscale::new_scale_color() +
  geom_sf(data = pts, aes(color = CODIGO)) +
  scale_fill_manual(values = "palegreen3") +
  labs(title = "Spatial distribution of the stations")
```

# Cathment area

In this section, we define the water cathment area for each measurement sites. At this point we are only dissolving the cathment areas of rivers sections. 

```{r, results = F}
watersheds <- st_read(
  dsn = "../data/ANA-bacia_ottocodificada_5k/geoft_bho_2017_5k_area_drenagem.gpkg") %>% 
  st_transform(crs)

rivers <- st_read(
  dsn = "../data/ANA-bacia_ottocodificada_5k/geoft_bho_2017_5k_trecho_drenagem.gpkg") %>% 
  st_transform(crs)
```

The selection of the upstream watersheds we selected the stream section nearest to the sttion. This is alternative to select the watershed it is inserted; this way made more sense to me. then we selected all the upstream sections. We filtered the watersheds associated to this set of streams and dissolved them. We ran this process for all the stations.


```{r, results = F}
pts <- pts %>%
  mutate(nearest_river = rivers$cotrecho[st_nearest_feature(pts, rivers)])

for (i in pts$CODIGO) { 
  
  pt <- pts %>% filter(CODIGO == i)
  
  r0 <- rivers %>% 
    filter(rivers$cotrecho == pt$nearest_river)
  
  rf <- r0
  
  r <- rivers %>%
    filter(nutrjus %in% r0$cotrecho)
  
  rf <- rbind(rf, r)
  
  while (nrow(r) > 0) {
    
    r <- rivers %>%
      filter(nutrjus %in% r$cotrecho)
    
    rf <- rbind(rf, r)
    
  }
  
  if (i == pts$CODIGO[1]) {
    
    wf <- watersheds %>%
      filter(cobacia %in% rf$cobacia) %>%
      summarise(code = pt$CODIGO)
    
  } else {
    
    wf_ <- watersheds %>%
      filter(cobacia %in% rf$cobacia) %>%
      summarise(code = pt$CODIGO)
    
    wf <- rbind(wf, wf_)
    
  }
  
}

wf <- wf %>% 
  mutate(area = as.numeric(st_area(wf) * 1e-6))
st_write(wf, "../data_process/catchment_areas.shp", delete_layer = T)
```

The results were checked in a GIS and they are working fine. It takes about 6 hours to run it all.

## Summary of the results

```{r}
wf %>%
  ggplot(aes(area)) +
  geom_histogram() +
  scale_x_log10() +
  labs(title = "Histogram of watersheds' area",
       x = "area (sq. km)")

```

```{r include=F, results=F}
wf_subset <- wf %>%
  filter(area <= 2000)

wf_subset %>%
  st_transform(crs = 4326) %>% 
  st_write("../data_process/catchment_areas2.shp", delete_layer = T)
```

After subseting the watersheds with area smaller than 2,000 sq. km, we have `r nrow(wf_subset)` samples.

```{r}
wf_subset %>%
ggplot() +
  geom_sf(data = amazon, fill = "palegreen3", aes(color = "Amazon")) +
  geom_sf(aes(fill = code)) +
  scale_fill_viridis_c() +
  labs(title = "Spatial distribution of the selected watersheds")
```

# Fires (TO BE UPDATED)

We got fire data from [Firms](https://firms.modaps.eosdis.nasa.gov/), downloaded in June 11, 2020.

```{r eval=F, include=F}
# wf_subset <- st_read("../data_process/catchment_areas.shp") %>%
#   filter(area < 2000)
# st_crs(wf_subset) <- crs
```

```{r include=F, results = F}
fire <- st_read("../data/DL_FIRE_M6_132041/fire_archive_M6_132041.shp")
```

```{r, results = F}
fire <- fire %>%
  filter(SATELLITE == "Terra") %>%
  mutate(ACQ_DATE = ymd(ACQ_DATE)) %>%
  filter(year(ACQ_DATE) == 2019) %>%
  st_transform(crs)
```

```{r message=F, warning=F, include = F}
fire2 <- fire[wf_subset, ]

fire2 <- st_join(fire2, wf_subset["code"])

fire2 <- fire2 %>%
  st_drop_geometry() %>%
  group_by(code) %>%
  summarise(n = n())

wf_subset <- wf_subset %>%
  left_join(fire2) %>%
  mutate(n = if_else(!is.na(n), n, as.integer(0)))

```

```{r}
wf_subset %>% 
  ggplot() +
  geom_sf(data = amazon, fill = "gray", aes(color = "Amazon")) +
  geom_sf(aes(fill = n), color = NA) +
  scale_fill_viridis_c(option = "inferno",
                       trans = scales::log10_trans()) +
  labs(title = "Number of fires in 2019")
```

```{r}
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

wf_subset %>%
  mutate(outlier = ifelse(is_outlier(n), code, as.numeric(NA))) %>%
  ggplot(aes(y = n, x = 0, label = outlier)) +
  geom_boxplot() + 
  geom_text(na.rm = TRUE, hjust = -0.3) +
  scale_y_continuous(breaks = seq(0, 60, 10))
```
```{r}
wf_subset %>%
  mutate(outlier = ifelse(is_outlier(n), code, as.numeric(NA))) %>%
  ggplot(aes(y = n, x = 0, label = outlier)) +
  geom_boxplot() + 
  geom_text(na.rm = TRUE, hjust = -0.3) +
  scale_y_log10()
```

```{r}
summary(wf_subset$n)
```

# Land use and land cover data

This data comes from Mapbiomas v4.1. The data is available at GEE. In GEE, I have calculated the area in hectares in 2018 for the following classes: (1) Forest - natural forests -, (2) Non-forest - combination of non-forest, but natural land cover eg. Water, grassland, beaches and others -, (3) Antropic - deforested areas -, and (4) Clouds - non observed areas because of cloud cover.

```{r, include = F}
lulc <- read_csv("../data_process/output_gee-2018.csv", 
                  guess_max = 20000) %>%
  select(-.geo, -'system:index') %>%
  mutate(perc_antropic_2018 = (antropic_2018 / total_area) * 1e2) 

wf_subset <- wf_ %>%
  left_join(lulc)
```

```{r}
wf_subset %>%
  select(ends_with("2018")) %>%
  summary()
```

We do not have unobserved areas in the watersheds. Good!

Also, we have a pretty decent variation in all other classes.

```{r}
wf_subset %>%
  ggplot(aes(antropic_2018)) +
  geom_histogram() +
  labs(x = "Accumulated desforested area (ha)")
```

```{r}
wf_subset %>%
  ggplot(aes(perc_antropic_2018)) +
  geom_histogram() +
  labs(x = "Desforested area (%)")
```


```{r}
# FIX HERE
# wf_subset %>%
#   ggplot(aes(x = perc_antropic_2018, y = n / area)) +
#   geom_point()
```


# Streamflow data

Here I contrast the CDF of disturbed and control watersheds to check the if there is any differences. We can use as dependent variable the median of the CDF or the difference in the areas under the curve. 

I have downloaded data from http://www.snirh.gov.br/hidroweb/serieshistoricas for all the `r nrow(wf)` water stations.

```{r echo=F, message=F, warning=F}
wf %>%
  st_drop_geometry() %>%
  write_csv("../data_process/wf.csv")
```

```{r message=FALSE, warning=FALSE, include=FALSE}
dns <- list.files("../data/Medicoes_convencionais-full/",
                  recursive = T, full.names = T, pattern = "*vazoes")
```

However, we have data on streamflow for `r lenght(dns)` of them.

```{r}
wf_ <- str_sub(dns, -12, -5)
wf_ <- wf %>% filter(wf$code %in% wf_)

```

Let's see the size of the watersheds to be considered depending on the number of samples we need.

```{r}
wf_ %>%
  arrange(area) %>%
  mutate(n = as.numeric(row.names(.))) %>%
  ggplot(aes(x = n, y = area)) +
  geom_point() +
  scale_y_log10() +
  labs(y = expression(Area~(km^{2})),
       x = "Sample size")
```

```{r}
wf_ <- wf_ %>%
  arrange(area) %>%
  filter(as.numeric(row.names(.)) <= 100)

wf_ %>%
  st_transform(crs = 4326) %>%
  st_write("../data_process/catchment_areas3.shp", delete_layer = T)
```


```{r echo=F, message=F, warning=F}
for (i in seq_along(dns)) {

  if (i == 1) {

    hydro <- read_csv2(dns[i], skip = 13, guess_max = 2000) %>%
      mutate(date = dmy(Data)) %>%
      select(code = EstacaoCodigo, date, starts_with("Vazao"), -ends_with("Status")) %>%
      pivot_longer(starts_with("Vazao")) %>%
      mutate(day = str_sub(name, -2, -1),
             date = date + days(day) - 1)

  } else {

    hydro <- read_csv2(dns[i], skip = 13, guess_max = 2000) %>%
      mutate(date = dmy(Data)) %>%
      select(code = EstacaoCodigo, date, starts_with("Vazao"), -ends_with("Status")) %>%
      pivot_longer(starts_with("Vazao")) %>%
      mutate(day = str_sub(name, -2, -1),
             date = date + days(day) - 1) %>%
      bind_rows(hydro)

  }

}

hydro <- hydro %>%
  left_join(st_drop_geometry(wf_subset)) %>%
  filter(code %in% wf_$code)

```

The following code coverts from cubic meters per second to milimeters per day.

```{r}
hydro <- hydro %>%
  mutate(value_mmd = value / (area * 1e6) * 24 * 60 * 60 * 1000)
```


Looks a bit random, but other factors are playing a role here.

```{r}
hydro_summary <- hydro %>%
  group_by(code) %>%
  summarise(date_min = min(date),
            date_max = max(date),
            date_med = median(date),
            perc_antropic_2018 = max(perc_antropic_2018))

hydro_summary %>%
  ggplot(aes(x = date_med, y = as.character(code), color = perc_antropic_2018)) +
  geom_linerange(aes(xmin = date_min, xmax = date_max), size = 1.3) +
  scale_color_viridis_c(trans = scales::log1p_trans()) +
  labs(x = "Year", y = "Watershed code", color = "Acc. deforestation (%)")
```


## Task requested by Taehee in Jun 22, 2020.

Select \~2 watershed to show the empirical cumulative distribution function (ECDF) before and after 2004, when deforestation started to decrease sharply.

I am going to manualy select the watersheds 13600002, 13470000, 17350000, 17345000, 14280001. The criteria was long term data and different levels of disturbance.

```{r}
selection <- c(13600002, 13470000, 17350000, 17345000, 14280001)

wf_subset %>% 
  filter(code %in% selection) %>%
  ggplot() +
  geom_sf(data = amazon, fill = "gray", aes(color = "Amazon")) +
  geom_sf(aes(fill = as.character(round(perc_antropic_2018, 0))), color = NA) +
  scale_fill_viridis_d(option = "inferno") +
  labs(title = "Selection",
       color = "", fill = "Deforestation (%)") +
  theme(legend.position = "top")
```

```{r include=FALSE}
hydro_subset <- hydro %>%
  filter(code %in% selection) %>%
  filter(year(date) >= 1988) %>%
  mutate(post = if_else(year(date) > 2004, 1, 0),
         perc_antropic_2018 = round(perc_antropic_2018, 0)) 
  
```

```{r}
hydro_subset %>%
  ggplot(aes(value_mmd, color = as.character(post), group = post)) +
  facet_wrap(vars(perc_antropic_2018), scales = "free") +
  stat_ecdf(size = 1.2) +
  scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_colour_viridis_d() +
  labs(title = "Empirical cumulative distribution function",
       y = "Cumulative Frequency",
       x = expression(mm~d^{-1}),
       color = "Post deforestation decline (2004)") + 
  theme(legend.position = "top")
```


### Same for fire

```{r}
hydro_summary2 <- hydro %>%
  group_by(code) %>%
  summarise(date_min = min(date),
            date_max = max(date),
            date_med = median(date),
            fire = max(n)) %>%
  filter(year(date_min) <= 2018) %>%
  filter(year(date_max) >= 2020)

hydro_summary2 %>%
  ggplot(aes(x = date_med, y = as.character(code), color = fire)) +
  geom_linerange(aes(xmin = date_min, xmax = date_max), size = 1.3) +
  scale_color_viridis_c() +
  labs(x = "Year", y = "Watershed code", color = "Active fire pixels")
```

```{r}
selection <- hydro_summary2$code

wf_subset %>% 
  filter(code %in% selection) %>%
  ggplot() +
  geom_sf(data = amazon, fill = "gray", aes(color = "Amazon")) +
  geom_sf(aes(fill = as.character(n)), color = NA) +
  scale_fill_viridis_d(option = "inferno") +
  labs(title = "Selection",
       color = "", fill = "Active fire pixels") +
  theme(legend.position = "top")
```

```{r include=FALSE}
hydro_subset2 <- hydro %>%
  filter(code %in% selection) %>%
  filter(date >= date_decimal(2018.5)) %>%
  filter(date <= date_decimal(2020.5)) %>%
  mutate(post = if_else(date > date_decimal(2019.5), 1, 0),
         fire = n) 
  
```

```{r}
hydro_subset2 %>%
  ggplot(aes(value_mmd, color = as.character(post), group = post)) +
  facet_wrap(code + fire ~ ., scales = "free") +
  stat_ecdf(size = 1.2) +
  scale_x_log10(labels = scales::trans_format("log10", scales::math_format(10^.x))) +
  scale_colour_viridis_d() +
  labs(y = "Cumulative Frequency",
       x = expression(mm~d^{-1}),
       color = "Post fire outbreak") + 
  theme(legend.position = "top")
```

## Tentative paired catchment analysis

Task requested by Taehee in Jul 16, 2020.

Selecting 2 watersheds in Rondonia

```{r}
selection <- c(15490500, 15248010, 15344000, 15590000, 15550000, 15575000)

hydro_summary %>%
  filter(code %in% selection) %>%
  ggplot(aes(x = date_med, y = as.character(code), color = perc_antropic_2018)) +
  geom_linerange(aes(xmin = date_min, xmax = date_max), size = 1.3) +
  scale_color_viridis_c(trans = scales::log1p_trans()) +
  labs(x = "Year", y = "Watershed code", color = "Acc. deforestation (%)")

```

Gather the data as in the ecohydrology lab 3

```{r}
selection <- c(15550000, 15248010)

pca <- hydro %>%
  filter(code %in% selection) %>%
  group_by(year = year(date), perc_antropic_2018) %>%
  summarise(value_mmd = mean(value_mmd, na.rm = T)) %>%
  ungroup() %>%
  mutate(
    # post = case_when(
    # year >= 2008 ~ "post",
    # year < 2008 & year > 1993 ~ "deforestation",
    # year <= 1993 ~ "pre"),
    treat = if_else(perc_antropic_2018 > 20, "Treatment", "Control")
    ) %>%
  select(-perc_antropic_2018) %>%
  pivot_wider(names_from = treat, values_from = value_mmd) %>%
  filter(year >= 1983) %>%
    mutate(
      post = case_when(
        year >= 2008 ~ "post",
        year < 2008 & year > 1995 ~ "deforestation",
        year <= 1995 ~ "pre")
    )
```

```{r message=FALSE, warning=FALSE}
pca %>%
  ggplot(aes(x = Control*365, y = Treatment*365, color = post)) +
  geom_point() + geom_smooth(method = lm) +
  geom_abline(intercept = 0, slope = 1) + 
  scale_x_continuous(limits = c(0, 1.3e3)) +
  scale_y_continuous(limits = c(0, 1.3e3)) +
  labs(x = "Control (mm / yr)",
       y = "Treatment (mm / yr)") +
  theme(aspect.ratio = 1)
```

